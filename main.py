import requests
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel

app = FastAPI()

# CORS Õ¯Õ¡Ö€Õ£Õ¡Õ¾Õ¸Ö€Õ¸Ö‚Õ´
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# --- Õ”Õˆ ÕÕÕ…Ô±Ô¼Õ†ÔµÕÔ¸ ---
GROQ_API_KEY = "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".strip()
TELEGRAM_TOKEN = "8221855314:AAF0_IOSpZaHamW_YUr3n5QYXV_iXVWt1nQ"
MY_CHAT_ID = "8221855314"

class ChatRequest(BaseModel):
    message: str

@app.post("/chat")
async def chat(req: ChatRequest):
    try:
        # Llama 3 API (Groq) Õ°Õ¡Õ½ÖÕ¥Õ¶
        url = "https://api.groq.com/openai/v1/chat/completions"
        
        headers = {
            "Authorization": f"Bearer {GROQ_API_KEY}",
            "Content-Type": "application/json"
        }
        
        payload = {
            "model": "llama-3.3-70b-versatile", 
            "messages": [
                {
                    "role": "system", 
                    "content": "Ô´Õ¸Ö‚ Smart Content AI Õ¨Õ¶Õ¯Õ¥Ö€Õ¸Ö‚Õ©ÕµÕ¡Õ¶ ÕºÖ€Õ¸Ö†Õ¥Õ½Õ«Õ¸Õ¶Õ¡Õ¬ Ö…Õ£Õ¶Õ¡Õ¯Õ¡Õ¶Õ¶ Õ¥Õ½:"
                    " Ô½Õ¸Õ½Õ«Ö€ Õ´Õ«Õ¡ÕµÕ¶ Õ°Õ¡ÕµÕ¥Ö€Õ¥Õ¶: Õ½Õ¯Õ¦Õ¢Õ¸Ö‚Õ´ Õ¶Õ¥Ö€Õ¯Õ¡ÕµÕ¡ÖÕ«Ö€ Õ¸Ö€ÕºÕ¥Õ½ SmartContentAI Ö…Õ£Õ¶Õ¡Õ¯Õ¡Õ¶ Õ¥Õ©Õ¥ Ö„Õ¥Õ¦ Õ°Õ¡Ö€ÖÕ¶Õ¥Õ¶ Õ©Õ¥ Õ¸Õ¾ Õ§ Ö„Õ¥Õ¦ Õ½Õ¿Õ¥Õ²Õ®Õ¥Õ¬"
                    "Õ„Õ¥Õ¶Ö„ Õ¦Õ¢Õ¡Õ²Õ¾Õ¸Ö‚Õ´ Õ¥Õ¶Ö„ AI Õ‰Õ¡Õ©Õ¢Õ¸Õ¿Õ¥Ö€Õ« Õ½Õ¿Õ¥Õ²Õ®Õ´Õ¡Õ´Õ¢ AI Õ¼Õ«Õ¬Õ½Õ¥Ö€Õ« Õ½Õ¿Õ¥Õ²Õ®Õ´Õ¡Õ´Õ¢, Ö‡ WEB Õ¯Õ¡ÕµÖ„Õ¥Ö€Õ« Õ½Õ¿Õ¥Õ²Õ®Õ´Õ¡Õ´Õ¢"
                    "Õ´Õ¥Õ¶Ö„ Õ¸Ö‚Õ¶Õ¥Õ¶Ö„ Õ«Õ¶Õ½Õ¿Õ¡Õ£Ö€Õ¡Õ´ÕµÕ¡Õ¶ Õ§Õ» smartcontent_ai"
                    "Õ¥Õ²Õ«Ö€ Õ°Õ¡Õ³Õ¡Õ­Õ¸Ö€Õ¤Õ« Õ°Õ¥Õ¿ Õ¢Õ¡Ö€Õ¥Õ°Õ¡Õ´Õ¢ÕµÕ¸Ö‚Ö€ Ö‡ ÕºÕ¡Õ¿Õ¡Õ½Õ­Õ¡Õ¶Õ«Ö€ Õ°Õ¡Ö€ÖÕ¥Ö€Õ«Õ¶"
                    "Õ½Õ¿Õ¡Õ¶Õ¤Õ¡Ö€Õ¿ ÖƒÕ¡Õ©Õ¥Õ©Õ« Õ¡Ö€ÕªÕ¥Ö„Õ¨ 40-80.000 Õ¤Ö€Õ¡Õ´ Õ§ Õ¡Õ´Õ½Õ¡Õ¯Õ¡Õ¶ Õ½ÕºÕ¡Õ½Õ¡Ö€Õ¯Õ´Õ¡Õ¶ Õ¾Õ³Õ¡Ö€ 10,000Õ¤Ö€Õ¡Õ´ Õ¯Õ¡Õ­Õ¾Õ¡Õ® Õ¢Õ¡Ö€Õ¤Õ¸Ö‚Õ©ÕµÕ¸Ö‚Õ¶Õ«Ö, Õ¶Õ¥Ö€Õ¡Õ¼Õ¸Ö‚Õ´ Õ§ 1  AI CHATBOT"
                    "Ô²Õ«Õ¦Õ¶Õ¥Õ½ ÖƒÕ¡Õ©Õ¥Õ© AI Õ‰Õ¡Õ© Õ¢Õ¸Õ¿, 5 AI Õ€Õ¸Õ¬Õ¸Õ¾Õ¡Õ¯Õ¶Õ¥Ö€, 1 Õ¾Õ¥Õ¢ Õ¯Õ¡ÕµÖ„(landing) Õ¡Ö€ÕªÕ¥Ö„Õ¨ 180â€¤000Õ¤Ö€Õ¡Õ´, Õ¡Õ´Õ½Õ¡Õ¯Õ¡ Õ½ÕºÕ¡Õ½Õ¡Ö€Õ¯Õ´Õ¡Õ¶ Õ¾Õ³Õ¡Ö€Õ¨ 20,000Õ¤Ö€Õ¡Õ´"
                    "Õ§Ö„Õ½ÕºÕ¥Ö€Õ¿ ÖƒÕ¡Õ©Õ¥Õ©Õ¨ Õ¶Õ¥Ö€Õ¡Õ¼Õ¸Ö‚Õ´ Õ§ 2 AI Õ¹Õ¡Õ© Õ¢Õ¸Õ¿, 1 Õ¾Õ¥Õ¢ Õ¯Õ¡ÕµÖ„, 1 Õ¡Õ´Õ«Õ½ Õ¡Õ¶Õ¾Õ³Õ¡Ö€ Õ½ÕºÕ¡Õ½Õ¡Ö€Õ¯Õ¸Ö‚Õ´, Õ¡Ö€ÕªÕ¥Ö„Õ¨ 300,000 Õ¤Ö€Õ¡Õ´"
                    

                },
                {
                    "role": "user", 
                    "content": req.message
                }
            ],
            "temperature": 0.7 # ÕŠÕ¡Õ¿Õ¡Õ½Õ­Õ¡Õ¶Õ« Õ½Õ¿Õ¥Õ²Õ®Õ¡Õ£Õ¸Ö€Õ®Õ¡Õ¯Õ¡Õ¶ Õ¡Õ½Õ¿Õ«Õ³Õ¡Õ¶Õ¨
        }
        
        response = requests.post(url, json=payload, headers=headers)
        res_data = response.json()

        # ÕÕ¿Õ¸Ö‚Õ£Õ¸Ö‚Õ´ Õ¥Õ¶Ö„ ÕºÕ¡Õ¿Õ¡Õ½Õ­Õ¡Õ¶Õ¨ (Llama-Õ¶ Ö…Õ£Õ¿Õ¡Õ£Õ¸Ö€Õ®Õ¸Ö‚Õ´ Õ§ OpenAI-Õ« Ö†Õ¸Ö€Õ´Õ¡Õ¿Õ¨)
        if "choices" in res_data:
            bot_reply = res_data["choices"][0]["message"]["content"]
        elif "error" in res_data:
            bot_reply = f"Llama Error: {res_data['error']['message']}"
        else:
            bot_reply = "Õ‰Õ¯Õ¡Ö€Õ¸Õ²Õ¡ÖÕ¡ Õ¯Õ¡Õº Õ°Õ¡Õ½Õ¿Õ¡Õ¿Õ¥Õ¬ "

        # Telegram-Õ« Õ°Õ¡Õ¿Õ¾Õ¡Õ® (Õ¶Õ¸Ö‚ÕµÕ¶Õ¶ Õ§ Õ´Õ¶Õ¸Ö‚Õ´)
        if any(char.isdigit() for char in req.message) and len(req.message) > 7:
            tg_url = f"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendMessage"
            requests.post(tg_url, json={
                "chat_id": MY_CHAT_ID, 
                "text": f"ğŸš€ Õ†Õ¸Ö€ Õ°Õ¡ÕµÕ¿ Llama-Õ«Ö!\nğŸ’¬ Õ€Õ¡Õ³Õ¡Õ­Õ¸Ö€Õ¤: {req.message}"
            })

        return {"reply": bot_reply}

    except Exception as e:
        return {"reply": f"Õ€Õ¡Õ´Õ¡Õ¯Õ¡Ö€Õ£Õ¡ÕµÕ«Õ¶ Õ½Õ­Õ¡Õ¬: {str(e)}"}

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="127.0.0.1", port=8000)